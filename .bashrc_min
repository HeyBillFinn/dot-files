# Don't merge
set -o vi
export EDITOR=vim

PERSISTENT_HISTORY_FILE="$HOME/dot-files/.persistent_history"
HISTTIMEFORMAT="%F %T "
log_bash_persistent_history()
{
  [[
  $(history 1) =~ ^\ *[0-9]+\ +([^\ ]+\ [^\ ]+)\ +(.*)$
  ]]
  local date_part="${BASH_REMATCH[1]}"
  # Replace newlines with blank space and trim trailing spaces
  local command_part=$(echo "${BASH_REMATCH[2]}" | tr '\n' ' ' | sed -e 's/[[:space:]]*$//')
  if [ "$command_part" != "$PERSISTENT_HISTORY_LAST" ] && \
    [[ $command_part != "phgrep "* ]]
  then
    if [[ $command_part == "ph "* ]]
    then
      parsed_command=$(echo $command_part | awk '{print $2}')
      command_part=$(_ph_get_command $parsed_command)
    fi
    echo $date_part "|" $HOSTNAME "|" $PWD "|" "$command_part" >> $PERSISTENT_HISTORY_FILE
    export PERSISTENT_HISTORY_LAST="$command_part"
  fi
}

# Stuff to do on PROMPT_COMMAND
run_on_prompt_command()
{
  log_bash_persistent_history
}

_ph_get_command()
{
  if [ "$#" -ne 1 ]; then
    echo "Illegal number of parameters"
  else
    if ! [[ $1 =~ ^-?[0-9]+$ ]]; then
      echo "Illegal non-integer argument."
    else
      command=`sed "$1!d" $PERSISTENT_HISTORY_FILE | awk -F "|" '{print $4}'`
      echo $command
    fi
  fi
}

ph()
{
  if [ "$#" -ne 1 ]; then
    echo "Illegal number of parameters"
  else
    command=$(_ph_get_command $1)
    echo $command
    eval $command
  fi
}

phe()
{
  if [ "$#" -ne 1 ]; then
    echo "Illegal number of parameters"
  else
    command=$(_ph_get_command $1)
    echo $command
  fi
}

__fzf_persistent_history__() (
  local cmd
  # XXX: Currently requires `vipe` and `sponge` of `moreutils`.
  tac $PERSISTENT_HISTORY_FILE | \
    fzf --tiebreak=index -d '\|' -n '4..' \
    --bind 'enter:execute(export FZF_CMD=$(echo {} | awk -F "|" '"'"'{print $4}'"'"'); echo "$FZF_CMD")+abort,ctrl-v:execute(export FZF_CMD=$(echo {} | awk -F "|" '"'"'{print $4}'"'"'); echo $FZF_CMD | vipe)+abort,ctrl-d:execute(export FIRST_THREE_COLS=$(echo {} | cut -d "|" -f1-3); export OUT_FILENAME=$(echo ~/dot-files/$(date -u -Iseconds)_bkp.persistent_history); cp ~/dot-files/.persistent_history $OUT_FILENAME && grep -v -a -F "$FIRST_THREE_COLS" ~/dot-files/.persistent_history | sponge ~/dot-files/.persistent_history)+abort'
)
# Heavily inspired from ~/.fzf/shell/key-bindings.bash
bind '"\C-x\C-a": vi-movement-mode'
bind '"\C-x\C-e": shell-expand-line'
bind '"\C-x\C-r": redraw-current-line'
bind '"\C-x^": history-expand-line'
bind '"\C-p": "\C-x\C-addi`__fzf_persistent_history__`\C-x\C-e\C-x\C-r\C-x^\C-x\C-a$a\n"'

gitmv()
{
  git grep -l "$1" | xargs sed -i "s/$1/$2/g"
}

gitfixup()
{
  git commit --fixup=$1
  git rebase -i --autosquash $1~1
}

gitpushtmp()
{
  branchName=$(git rev-parse --abbrev-ref HEAD)
  if ! [[ $branchName =~ ^dev.*$ ]]; then
    echo "error: not on dev branch"
    return 1
  fi
  tmpBranchName=$(echo $branchName | sed 's/^dev/tmp/')
  branchExists=$(git rev-parse --verify $tmpBranchName 2>/dev/null)
  if [[ -z $branchExists ]]; then
    echo "branch $tmpBranchName doesn't exist; creating"
    git branch $tmpBranchName
  fi
  echo "updating $tmpBranchName to $branchName"
  git branch -f $tmpBranchName $branchName
  echo "force pushing $tmpBranchName"
  if ! [[ $tmpBranchName =~ ^tmp.*$ ]]; then
    echo "error: tmp branch incorrectly formatted"
    return 1
  fi
  git push -u origin $tmpBranchName -f
}

alias nt='nosetests -s --with-progressive --logging-level=INFO'

PROMPT_COMMAND="run_on_prompt_command"
#  \*(Ps = \*3\*0 \(-> Set foreground color to Black.
#  \*(Ps = \*3\*1 \(-> Set foreground color to Red.
#  \*(Ps = \*3\*2 \(-> Set foreground color to Green.
#  \*(Ps = \*3\*3 \(-> Set foreground color to Yellow.
#  \*(Ps = \*3\*4 \(-> Set foreground color to Blue.
#  \*(Ps = \*3\*5 \(-> Set foreground color to Magenta.
#  \*(Ps = \*3\*6 \(-> Set foreground color to Cyan.
#  \*(Ps = \*3\*7 \(-> Set foreground color to White.
#  \*(Ps = \*3\*9 \(-> Set foreground color to default (original).
#  \*(Ps = \*4\*0 \(-> Set background color to Black.
#  \*(Ps = \*4\*1 \(-> Set background color to Red.
#  \*(Ps = \*4\*2 \(-> Set background color to Green.
#  \*(Ps = \*4\*3 \(-> Set background color to Yellow.
#  \*(Ps = \*4\*4 \(-> Set background color to Blue.
#  \*(Ps = \*4\*5 \(-> Set background color to Magenta.
#  \*(Ps = \*4\*6 \(-> Set background color to Cyan.
#  \*(Ps = \*4\*7 \(-> Set background color to White.
#  \*(Ps = \*4\*9 \(-> Set background color to default (original).

if [[ $HOSTNAME == "vagrant"* ]]
then
  PS1="\[\033[37m\]\t\[\033[m\]-\[\033[36m\]\u\[\033[m\]@\[\033[32m\]\h:\[\033[33;1m\]\w\[\033[m\]\$ "
fi
alias disablebracketedpaste='printf "\e[?2004l"'
alias phgrep='cat $PERSISTENT_HISTORY_FILE|grep --color -n -a'
alias ag='ack-grep --ignore-dir dist --ignore-file=ext:patch'
alias agt='find . -name "*.py" -type f | xargs ls -tr1 | xargs ag '
alias k='fc -s'
bind "set completion-ignore-case on"
bind "set show-all-if-ambiguous on"

alias gdm='git diff master...HEAD'
alias glm='git log -p master...HEAD'
alias gg='git grep -n '
alias gpush='git push -u origin HEAD'
alias grebase='gmaster && git checkout - && git rebase master'
alias gamend='git commit --amend --no-edit'
alias gm='git checkout master'
alias gfa='git fetch --all'
alias gmr='git merge --ff-only @{u}'
alias gmaster='git checkout master && git fetch --all && git merge --ff-only @{u}'
alias src='source ~/.bashrc'
alias alembicc='alembic -c ~/Projects/Angaza/alembic.ini '
alias alembichistory='alembicc history | less'
alias alembichead='alembicc upgrade head'
alias sandboxdemodb='export ZA_SANDBOX_DEMO_DATABASE_URI=`envdir ~/Projects/Angaza/variables.aws summon -f ~/Projects/Angaza/payg-backend/za/secrets.yml -e sandbox -D ENV=sandbox-demo printenv | grep "^DATABASE_URI=" | cut -d "=" -f 2`'
alias proddb='export ZA_PROD_DATABASE_URI=`cd payg-deploy > /dev/null && summon -e PRODUCTION printenv | grep "^DATABASE_URI=" | cut -d "=" -f 2`'
alias analyticsdb='export ZA_ANALYTICS_DATABASE_URL=`envdir ~/Projects/Angaza/variables.aws summon -f ~/Projects/Angaza/payg-backend/buildkite/periodic-tasks/check-follower-lag-secrets.yml printenv | grep "^ANALYTICS_FOLLOWER_DATABASE_URL=" | cut -d "=" -f 2`'
alias exportdb='export ZA_EXPORT_DATABASE_URL=`envdir ~/Projects/Angaza/variables.aws summon -f ~/Projects/Angaza/payg-backend/buildkite/periodic-tasks/check-follower-lag-secrets.yml printenv | grep "^EXPORTS_FOLLOWER_DATABASE_URL=" | cut -d "=" -f 2`'
alias followerdb='export ZA_FOLLOWER_DATABASE_URL=`cd payg-deploy > /dev/null && summon -e follower printenv | grep "^DATABASE_URI=" | cut -d "=" -f 2`'
alias heybillfinndb='export ZA_HEYBILLFINN_FORK_URL=`cd payg-deploy > /dev/null && summon -f ~/Projects/Angaza/payg-deploy/secrets.yml -e heroku_admin heroku config --app angaza-production | grep HEYBILLFINN | awk '"'"'{print $2}'"'"'`'
alias ec2instances='export ZA_EC2_INSTANCES=`ec2-host`'
alias ensure_bill='export ZA_BILL_INSTANCE=`cd payg-deploy > /dev/null && fab group_list_all:production,deploy | grep billfinn | cut -d " " -f 1`'
alias bizinstance='export ZA_BIZ_INSTANCE=`ec2-host | grep production__biz- | sed "s/\(.*\)\s\+\(.*\)/\2/g"`'
#alias sshprod='ec2-ssh `fab group_list_all | grep production__biz | cut -d '"'"' '"'"' -f 1`'
alias sshprod='ec2-ssh `fab group_list_all:production | grep "^production__biz" | awk "{print $1}"`'
alias alembicbranchpoint='AL_HISTORY=`alembic history` && AL_BR_REVISION=`echo "$AL_HISTORY" | grep "(branchpoint)" | awk '"'"'{print $3}'"'"'` && echo "branchpoint: $AL_BR_REVISION" && echo "$AL_HISTORY" | grep -C 1 "^$AL_BR_REVISION\|(head)"'
alias f8='flake8 --show-source --config=flake8.ini za'
alias vssh='vagrant ssh'
alias celerydemo='celery purge -f && AWS_ACCESS_KEY_ID=`cat ~/Projects/Angaza/variables.deploy/AWS_ACCESS_KEY_ID` AWS_SECRET_ACCESS_KEY=`cat ~/Projects/Angaza/variables.deploy/AWS_SECRET_ACCESS_KEY` DATABASE_URI=postgres:///za_sandbox celery --app=za worker --loglevel=INFO --concurrency=1 -Q celery,batch 2>&1 | tee ~/celery.log'
alias celeryprodbeat='ZA_CELERY_BROKER_URL=amqp://guest@localhost:5672 DATABASE_URI=postgres:///za_prod_snapshot celery --app=za beat --loglevel=INFO'
alias countries='python -c "from babel import Locale; l = Locale('"'"'en'"'"', '"'"'US'"'"'); print((u'"'"'\n'"'"'.join([u'"'"'{}:{}'"'"'.format(k, v) for (k, v) in l.territories.iteritems()])).encode('"'"'utf-8'"'"'))" | sort | less'
alias utcdate='date -u +%Y%m%dT%H%M%SZ'
alias utcclip='date -u +%Y%m%d | tr -d "\n" | xsel --clipboard'
alias isodate='date -u +%Y-%m-%dT%H:%M:%SZ'
alias justdate='date +%Y-%m-%d'
alias filenamedate='date +%Y-%m-%d_%H%M%SZ'
alias fabwheelupload='fab wheelhouse_upload:`ls -m ~/Projects/Angaza/payg-backend/*.whl | tr -d " " | tr -d "\n"`'
alias ec2host='envdir ~/Projects/Angaza/variables.aws ec2-host'
alias listgroups='cd ~/Projects/Angaza/payg-deploy && fab group_list_all:production'
alias demoserve='envdir ../variables.aws/ envdir ../variables.demo/ za-serve-gunicorn za.blueprints.admin:/raw za.blueprints.biz_api_internal:/api --workers 2'
alias zapsqldemo='DATABASE_URI="postgres:///za_demo" envdir ../variables.aws/ za-psql -u system@angaza.com'
alias followerserve='ensure_follower && DATABASE_URI=$ZA_FOLLOWER_DATABASE_URL za-serve-gunicorn za.blueprints.biz_api_internal:/api --workers 2 --timeout 120'
watchdb()
{
  watch $'psql -c "select pid,client_addr,client_port as port,substr(query_start::varchar, 1, 18),substr(query, 1, 50),substr(state, 1, 7),substr((now()-query_start)::varchar, 1, 8) as duration from pg_stat_activity where state != \'idle\' order by query_start;" '"$1"' '
}
watchprod()
{
  ensure_production
  watch $'psql -c "select pid,client_addr,client_port as port,substr(query_start::varchar, 1, 18),substr(query, 1, 50),substr(state, 1, 7),substr((now()-query_start)::varchar, 1, 8) as duration from pg_stat_activity where state != \'idle\' order by query_start;" $ZA_PROD_DATABASE_URI '
}
watchprodnarrow()
{
  ensure_production
  watch $'psql -c "select pid,client_addr,substr(query, 1, 50),substr((now()-query_start)::varchar, 1, 8) as duration from pg_stat_activity where state != \'idle\' order by query_start;" $ZA_PROD_DATABASE_URI '
}
stty -ixon
export VIRTUAL_ENV_DISABLE_PROMPT=1

celeryprod()
{
  if [ "$#" -ne 1 ]; then
    echo "Illegal number of parameters"
  else
    echo "rabbitmqadmin purge queue name=$1; celery purge -f && ZA_CELERY_BROKER_URL=amqp://guest@localhost:5672 DATABASE_URI=postgres:///za_prod_snapshot celery --app=za worker --hostname=$1 --loglevel=INFO --concurrency=1 --queues=$1 -Ofair 2>&1"
    rabbitmqadmin purge queue name=$1; celery purge -f && ZA_CELERY_BROKER_URL=amqp://guest@localhost:5672 DATABASE_URI=postgres:///za_prod_snapshot celery --app=za worker --hostname=$1 --loglevel=INFO --concurrency=1 --queues=$1
  fi
}

# set PATH so it includes user's private bin if it exists
if [ -d "$HOME/bin" ] ; then
    PATH="$HOME/bin:$PATH"
fi
shopt -s autocd
export CDPATH=.:~:~/Projects/Angaza

unregistered_unit()
{
  psql -d za_prod_snapshot -c "select default_account_number from units u left outer join accounts a on a.attached_unit_id=u.id where u.type='$1' and a.id is null order by u.id desc limit 10"
}
sshbill()
{
  if [[ -z "${ZA_BILL_INSTANCE}" ]]; then
    ensure_bill
  fi
  ec2-ssh -A $ZA_BILL_INSTANCE
}
scpbill()
{
  if [[ -z "${ZA_BILL_INSTANCE}" ]]; then
    ensure_bill
  fi
  scp $1 ubuntu@$ZA_BILL_INSTANCE:
}
safekill()
{
  pgrep -a $1
  killall -i $1
}
ensure_sandbox_demo()
{
  if [[ -z "${ZA_SANDBOX_DEMO_DATABASE_URI}" ]]; then
    sandboxdemodb
  fi
}
ensure_production()
{
  if [[ -z "${ZA_PROD_DATABASE_URI}" ]]; then
    proddb
  fi
}
ensure_follower()
{
  if [[ -z "${ZA_FOLLOWER_DATABASE_URL}" ]]; then
    followerdb
  fi
}
sql_statements()
{
  TRACE_ID="$1"
  CWD="$PWD"
  pushd ~/Projects/Angaza/payg-deploy
  envdir ~/Projects/Angaza/variables.deploy summon -e redshift psql -c 'select ''"time",duration,culprit,statement,parameters from sql_queries where trace_id='"'""$TRACE_ID""'" > "$CWD/$TRACE_ID.txt"
  popd
}
ensure_puce()
{
  if [[ -z "${ZA_PUCE_DATABASE_URL}" ]]; then
    export ZA_PUCE_DATABASE_URL=`cd payg-deploy > /dev/null && summon -e heroku_admin heroku config:get HEROKU_POSTGRESQL_PUCE_URL --app angaza-production`
  fi
}
ensure_heybillfinndb()
{
  if [[ -z "${ZA_HEYBILLFINN_FORK_URL}" ]]; then
    heybillfinndb
  fi
}
with_follower()
{
  ensure_follower
  psql -d $ZA_FOLLOWER_DATABASE_URL -c "$1"
}
orgs()
{
  with_follower "select o.id,name,default_operating_country,sms_sender_text,preferred_sms_router_id as router_id, aav.version_code as app_version from organizations o inner join agent_app_versions aav on o.agent_app_version_id=aav.id $* order by name"
}
products()
{
  with_follower "select id,name,type from products order by name"
}
agent_app_versions()
{
  with_follower "select o.name,aav.version_code,aav.requires_upgrade from organizations o inner join agent_app_versions aav on o.agent_app_version_id = aav.id order by o.name"
}
org_rels()
{
  with_follower "select p.name as parent, p.id as p_id, c.name as child, c.id as c_id from organization_organization_associations ooa inner join organizations p on ooa.parent_organization_id=p.id inner join organizations c on ooa.child_organization_id=c.id where p.name != 'Angaza' order by p.name,c.name"
}
users()
{
  with_follower "select u.id,u.created_when,username,o.name,substr(r.name, 1, 10),u.archived as ar,u.interface_locale as locale  from users u inner join organizations o on u.organization_id=o.id inner join roles r on u.role_id=r.id order by username"
}
roles()
{
  with_follower "select o.name,r.id,r.name from roles r inner join organizations o on r.organization_id=o.id order by o.name;"
}
roles_with_permissions()
{
  with_follower "select o.name,r.name,pd.title,p.is_enabled from permissions p inner join roles r on p.role_id=r.id inner join organizations o on r.organization_id=o.id inner join permission_descriptions pd on p.description_id=pd.id order by o.name,pd.title;"
}
groups()
{
  with_follower "select id,name from groups"
}
portals()
{
  with_follower "select o.name,o.id as org_id,p.id as portal_id,p.type,p.is_enabled,p.is_visible,p.reference_validation,p.remittance_detector,p.merchant_account from portals p inner join organizations o on p.organization_id=o.id order by o.name"
}
export_targets()
{
  with_follower "select et.id,et.type,o.name,etd.db_url,etd.schema,eth.* from export_targets et left outer join export_targets_http eth on et.id=eth.id left outer join export_targets_bigquery etb on et.id=etb.id left outer join export_targets_database etd on et.id=etd.id left outer join organizations o on exists(select 1 from export_report_configs erc where erc.export_target_id=et.id and erc.organization_id=o.id) order by et.id"
}
export_report_statuses()
{
  with_follower "select substr(ers.scheduled_when::varchar, 1, 16) as sched,substr(ers.started_when::varchar, 1, 16) as started,substring(ers.completed_when::varchar, 1, 16) as completed,ers.state,ers.size,erc.report_config_type,substr(erc.incremental_updated_when::varchar, 1, 16) as incr,erc.frequency,et.type, erc.organization_id as org_id from export_report_statuses ers inner join export_report_configs erc on ers.export_report_config_id=erc.id inner join export_targets et on erc.export_target_id=et.id where ers.scheduled_when > now() - '3 days'::interval order by ers.scheduled_when desc;"
}
export_report_configs()
{
  # with_follower "select erc.id,substr(erc.created_when::varchar, 1, 16) as created_when,substr(erc.frequency, 1, 10) as freq,substr(o.name, 1, 30) as org_name,erc.id,erc.report_config_type,et.type,erc.is_enabled as e,substr(erc.incremental_updated_when::varchar, 1, 10) as when,erc.table_reporter_kwargs,erc.db_kwargs,erc.report_kwargs from export_report_configs erc inner join organizations o on erc.organization_id=o.id inner join export_targets et on erc.export_target_id=et.id order by o.name"
  with_follower "select erc.id,substr(erc.created_when::varchar, 1, 10) as created,substr(erc.frequency, 1, 10) as freq,substr(o.name, 1, 30) as org_name,erc.report_config_type,et.type,erc.is_enabled as e,substr(erc.incremental_updated_when::varchar, 1, 16) as when from export_report_configs erc inner join organizations o on erc.organization_id=o.id inner join export_targets et on erc.export_target_id=et.id order by o.name"
}
sms_delivery()
{
  echo $1
  with_follower "select sm.organization_id,sr.type,sm.state,count(sm.id) from sms_messages sm inner join sms_routers sr on sm.router_id=sr.id where sm.recipient like '+$1%' and sm.created_when > now() - '1 hour'::interval group by 1,2,3 order by 1,2,3;"
}
seq_routers()
{
  with_follower "select srr.sequential_router_id as seq_id, srr.position as pos,sr.route,srrs.type,srrs.id as srrs_id,sr.id as sr_id,sr.description,round(sr.probability, 3) from sms_routers_routes srr inner join sms_routes sr on srr.route_id=sr.id inner join sms_routers srrs on sr.router_id=srrs.id order by srr.sequential_router_id,srr.position;"
}

zabill()
{
  cat << "EOF"

# Check all biz supervisor processes

for biz_host in `ec2-host | grep '^production__biz' | awk '{print $2}'`; do ssh -o "StrictHostKeyChecking no" ubuntu@$biz_host 'sudo supervisorctl status'; done;

# Helpful query for Support

with f as (select 36632404 as number) (select a.registration_date as effective_when,'registration' from accounts a inner join f on a.number=f.number) union (select p.effective_when,'payment' from payments p inner join accounts a on p.account_id=a.id inner join f on a.number=f.number) union (select bc.effective_when,'billing change' from billing_changes bc inner join accounts a on bc.account_id=a.id inner join f on a.number=f.number) order by 1;

# Fix screen ssh env var

export SSH_AUTH_SOCK=$(find /tmp/ssh-* -user `whoami` -name agent\* -printf '%T@ %p\n' 2>/dev/null | sort -k 1nr | sed 's/^[^ ]* //' | head -n 1)

# Badass redshift query to query queue depths

select generated_at,json_extract_path_text(regexp_replace(sll.message, '.*telemetry report; '), 'batch-sweep-db-fast') as fast, json_extract_path_text(regexp_replace(sll.message, '.*telemetry report; '), 'batch-sweep-db-slow') as slow, json_extract_path_text(regexp_replace(sll.message, '.*telemetry report; '), 'events-sms-low-prio') as low_prio from system_log_lines sll where message like '%telemetry report%' and generated_at > '2018-02-16 15:00' and generated_at < '2018-02-17@15:11' order by generated_at desc;

# Badass SQL query to get all time interval

with d as (select date_trunc('week', now()) - x.n * '1 week'::interval as t from (select generate_series(1, 10) as n) x) select d.t, count(a.id) from d left outer join accounts a on d.t=date_trunc('week', a.latest_payment_when) left outer join billings b on a.billing_id=b.id and b.type = 'LEGACY_PAYG' where b.id is not null group by d.t order by d.t desc;

with d as (select date_trunc('hour', now()) - x.n * '1 hour'::interval as hour from (select generate_series(1, 60*24*7) as n) x) select d.hour, count(r.id) from d left outer join receipts r on d.hour=date_trunc('hour', r.created_when) and type in ('PEGASUS_AIRTEL_UG') group by d.hour order by d.hour desc;

with d as (select date_trunc('day', now()) - x.n * '1 day'::interval as period from (select generate_series(1, 30) as n) x) select d.period, count(p.id) from d left outer join payments p on d.period=date_trunc('day', p.effective_when) and organization_id=30 group by d.period order by d.period desc;

with d as (select date_trunc('hour', now()) - x.n * '1 hour'::interval as period from (select generate_series(1, 24) as n) x) select d.period, sr.type, sm.state, count(sm.id) from d left outer join sms_messages sm on d.period=date_trunc('hour', sm.created_when) and sm.recipient like '+256%' left outer join sms_routers sr on sm.router_id=sr.id group by d.period,sr.type,sm.state order by d.period desc, sr.type, sm.state;

# Redshift version

with d as (select date_trunc('hour', sysdate) - n * '1 hour'::interval as hour from numbers_0_to_1e6 n where n >= 0 and n <= 24*7) select d.hour, count(hr.path) from d left outer join http_requests hr on d.hour=date_trunc('hour', hr.time) and path like '%hooks/pegasus/airtel' group by d.hour order by d.hour desc;

with d as (select date_trunc('hour', sysdate) - n * '1 hour'::interval as period from numbers_0_to_1e6 n where n >= 0 and n <= 24*7) select d.period, count(1) from d left outer join http_requests hr on d.period=date_trunc('hour', hr.time) and path like '%safaricom%' and code=499 group by d.period order by d.period desc;

with d as (select date_trunc('day', sysdate) - n * '1 hour'::interval as hour from numbers_0_to_1e6 n where n >= 0 and n <= 7) select d.hour, count(hr.path) from d left outer join http_requests hr on d.hour=date_trunc('day', hr.time) and path like '%hooks/pegasus/airtel' group by d.hour order by d.hour desc;

with d as (select date_trunc('day', sysdate) - n * '1 day'::interval as period from numbers_0_to_1e6 n where n >= 0 and n <= 90) select d.period, count(1) from d left outer join system_log_lines sll on d.period=date_trunc('day', sll.generated_at) and sll.message like '%Sentry responded with an error%' group by d.period order by d.period desc;

# SMS sequential routing config

select srr.sequential_router_id,srr.position,sr.route,srrs.type,srrs.id as srrs_id,sr.id as sr_id,sr.description,round(sr.probability, 3) from sms_routers_routes srr inner join sms_routes sr on srr.route_id=sr.id inner join sms_routers srrs on sr.router_id=srrs.id order by srr.sequential_router_id,srr.position;


envdir variables/ za-psql -u bill@angazadesign.com `cat ~/variables/DATABASE_URI`

select pid,client_addr,client_port as port,substr(query_start::varchar, 1, 18),substr(query, 1, 50),substr(state, 1, 7),substr((now()-query_start)::varchar, 1, 8) as duration from pg_stat_activity where state != 'idle' order by query_start;

select pid,client_addr,client_port,query_start,substr(query, 20),state from pg_stat_activity where state != 'idle' order by query_start;

select pid,application_name,client_addr,client_port,query_start,substr(query, 1, 50),state from pg_stat_activity where state != 'idle' order by query_start;

# View DB locks
select * from pg_locks where granted and relation = 'accounts'::regclass;

select pgsa.client_addr,pgl.locktype,pgl.database,pgl.relation,pgl.pid,pgl.mode,pgl.granted,pgl.fastpath from pg_locks pgl inner join pg_stat_activity pgsa on pgl.pid=pgsa.pid where granted and relation = 'users'::regclass;

select "time",duration,culprit from sql_queries where "time" > '2017-06-21 14:19:11'::timestamp and "time" < '2017-06-21 14:19:23' and process = 2088 order by 1;

from multiprocessing import Pool
import subprocess

def f(x):
    return subprocess.check_output(["fab", "group_delete:{}".format(x)])

p = Pool(5)
print(p.map(f, ["production__biz-20170804224549", "production__biz-20170808040138"]))

# Convert fields to autovalue
%s/final/abstract
%s/;/();/

# Convert auto-value functions to builder
%s/public abstract \(\S*\) \(\S*\)();/public abstract Builder \2\(\1 \2);
g/Nullable/d
g/SerializedName/d

sqlite3 /data/data/com.angazadesign.agent/databases/za-lite.db


select generated_at,json_extract_path_text(regexp_replace(message, '.*telemetry report; '), 'events-sms-low-prio') from system_log_lines where message like '%telemetry report;%' and generated_at > sysdate - '7 days'::interval order by 1;

# Deleting a bonus
a = Account.from_number(18052506)
assert len(a.bonuses) == 1
b = a.bonuses[0]
biz.g.session.delete(b)
biz.g.session.delete(b.activation)
u = a.attached_unit
x = u.compute_unit_status()
x.disable_when
u.activations
u.update_state()
a.update_billing_state(wipe_old=True)
biz.commit()

# Postgres Database table sizes

SELECT nspname || '.' || relname AS "relation",
    pg_size_pretty(pg_total_relation_size(C.oid)) AS "total_size"
  FROM pg_class C
  LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)
  WHERE nspname NOT IN ('pg_catalog', 'information_schema')
    AND C.relkind <> 'i'
    AND nspname !~ '^pg_toast'
  ORDER BY pg_total_relation_size(C.oid) DESC
  LIMIT 20;

# Set passwords to mine

update users set password_=(select password_ from users where id=422);

# Pretty print SQLAlchemy query

def prettyprintable(statement, dialect=None, reindent=True):
    """Generate an SQL expression string with bound parameters rendered inline
    for the given SQLAlchemy statement. The function can also receive a
    `sqlalchemy.orm.Query` object instead of statement.
    can 

    WARNING: Should only be used for debugging. Inlining parameters is not
             safe when handling user created data.
    """
    import sqlparse
    import sqlalchemy.orm
    if isinstance(statement, sqlalchemy.orm.Query):
        if dialect is None:
            dialect = statement.session.get_bind().dialect
        statement = statement.statement
    compiled = statement.compile(dialect=dialect,
                                 compile_kwargs={'literal_binds': True})
    return sqlparse.format(str(compiled), reindent=reindent)

print(prettyprintable(query.statement))

EOF
}
